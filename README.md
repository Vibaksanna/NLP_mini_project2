# Mini Project 2 â€“ Text Classification (NLP)

This project implements a sentiment classification system for product reviews.  
Each review is classified as **positive (1)** or **negative (0)** using multiple machine learning models and feature extraction techniques.

The project strictly follows the assignment requirements and includes:

- Correct **80% / 20% data split**
- Multiple models for comparison
- Accuracy-based evaluation
- A blind challenge dataset
- Proper output formatting

---

## ğŸ“ Project Structure

```
Text_Classification/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ positive-reviews.txt
â”‚   â”œâ”€â”€ negative-reviews.txt
â”‚   â”œâ”€â”€ positive-words.txt
â”‚   â”œâ”€â”€ negative-words.txt
â”‚   â””â”€â”€ challenge_data.txt
â”‚
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ best_model.pkl
â”‚   â”œâ”€â”€ tfidf_model.pkl
â”‚   â”œâ”€â”€ tfidf_vectorizer.pkl
â”‚   â””â”€â”€ submission.txt
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”œâ”€â”€ feature_extraction.py
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ train_tfidf.py
â”‚   â”œâ”€â”€ predict_challenge.py
â”‚   â””â”€â”€ predict_challenge_tfidf.py
â”‚
â”œâ”€â”€ venv/
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ§  Models Implemented

### Hand-Crafted Feature Models

- Logistic Regression
- Naive Bayes
- Random Forest

### TF-IDF Feature Model

- Logistic Regression (**best performing**)

---

## ğŸ“Š Accuracy Results

| Model                   | Features     | Accuracy   |
| ----------------------- | ------------ | ---------- |
| Naive Bayes             | Hand-crafted | 80.53%     |
| Logistic Regression     | Hand-crafted | 82.53%     |
| Random Forest           | Hand-crafted | 82.57%     |
| **Logistic Regression** | **TF-IDF**   | **91.31%** |

The TF-IDF + Logistic Regression model achieved the highest accuracy and was selected for the final challenge prediction.

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Create Virtual Environment

```bash
python -m venv venv
```

Activate it:

**Windows**

```bash
venv\Scripts\activate
```

**Linux / macOS**

```bash
source venv/bin/activate
```

---

### 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ Running the Project

### ğŸ”¹ Train hand-crafted feature models

```bash
python -m src.train
```

This will:

- Train Logistic Regression, Naive Bayes, and Random Forest
- Evaluate accuracy
- Save the best model to `output/best_model.pkl`

---

### ğŸ”¹ Train TF-IDF model (Recommended)

```bash
python -m src.train_tfidf
```

This will:

- Train TF-IDF + Logistic Regression
- Print accuracy
- Save:
  - `output/tfidf_model.pkl`
  - `output/tfidf_vectorizer.pkl`

---

### ğŸ”¹ Generate Challenge Predictions (FINAL)

```bash
python -m src.predict_challenge_tfidf
```

This will generate:

```
output/submission.txt
```

âœ” Exactly **5000 characters**  
âœ” No spaces  
âœ” No new lines  
âœ” `0 = negative`, `1 = positive`

---

## ğŸ“Œ Important Notes

- The **challenge_data.txt** file is **NOT used for training**
- Only the labeled datasets are split into training and testing sets
- Data splitting follows the **top 80% / bottom 20% rule**
- Accuracy is the only evaluation metric used
- The TF-IDF model is recommended for submission

---

## ğŸ§¾ Final Submission

Submit:

- `output/submission.txt`
- Source code (`src/`)
- Report PDF

---

## ğŸ Conclusion

This project demonstrates the importance of feature representation in sentiment analysis.  
While hand-crafted features provide reasonable performance, TF-IDF representations combined with Logistic Regression significantly improve accuracy and generalization.

---

**Author:**  
Mini Project 2 â€“ NLP Text Classification
